{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared data\n",
    "tdata = pd.read_csv('raw_data/merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # excluding non-European participants\n",
    "# mapping_IDs = pd.read_csv('raw_data/mapping_IDs.csv')\n",
    "# EUR_subjs = pd.read_csv('raw_data/ukb_European_PRSs.csv')\n",
    "# mapping_IDs = mapping_IDs[mapping_IDs['karin_id'].isin(EUR_subjs['FID'])]\n",
    "# tdata = tdata[tdata['eid'].isin(mapping_IDs['guido_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select CSA and CT data from prepared data\n",
    "area_items = pd.read_csv('raw_data/DK_CSA_items.csv')\n",
    "s1 = ['eid']\n",
    "for i in range(area_items.shape[0]):\n",
    "    s1.append(str(area_items.iloc[i,0])+'-2.0')\n",
    "CSA_data = tdata[s1].set_index('eid')\n",
    "\n",
    "thickness_items = pd.read_csv('raw_data/DK_CT_items.csv')\n",
    "s2= ['eid']\n",
    "for i in range(thickness_items.shape[0]):\n",
    "    s2.append(str(thickness_items.iloc[i,0])+'-2.0')\n",
    "CT_data = tdata[s2].set_index('eid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ALFF and ReHo data\n",
    "ALFF_data = pd.read_csv('raw_data/ALFF_DK_atlas.csv')\n",
    "ReHo_data = pd.read_csv('raw_data/ReHo_DK_atlas.csv')\n",
    "ALFF_data = ALFF_data.set_index('eid')\n",
    "ReHo_data = ReHo_data.set_index('eid')\n",
    "\n",
    "#match functional and structural brain data\n",
    "tmp_l = list(set(ALFF_data.index) & set(CT_data.index))\n",
    "CSA_data = CSA_data.loc[tmp_l]\n",
    "CT_data = CT_data.loc[tmp_l]\n",
    "\n",
    "ALFF_data = ALFF_data.loc[tmp_l]\n",
    "regions = area_items.iloc[:,1].values.tolist()\n",
    "ALFF_data = ALFF_data[regions]\n",
    "\n",
    "ReHo_data = ReHo_data.loc[tmp_l]\n",
    "regions = area_items.iloc[:,1].values.tolist()\n",
    "ReHo_data = ReHo_data[regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract covariates from prepared data\n",
    "df = pd.DataFrame({\"eid\" : tdata['eid']})\n",
    "df['Age'] = tdata['21003-2.0']\n",
    "df['Sex'] = tdata['31-0.0']\n",
    "df['IQ'] = tdata['20016-2.0']\n",
    "df['EA'] = tdata['6138-2.0']\n",
    "df['motion'] = tdata['25741-2.0']\n",
    "df['TCSA'] = tdata['26721-2.0'] + tdata['26822-2.0']\n",
    "df['ACT'] = tdata['26755-2.0'] + tdata['26856-2.0']\n",
    "df.set_index('eid',inplace=True)\n",
    "df = df.loc[tmp_l].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 19205\n",
      "min age: 45.0 max age: 81.0 mean age: 62.9747982296277 std age: 7.4390828237902165\n",
      "females: 9699 males: 9506\n"
     ]
    }
   ],
   "source": [
    "# print demographic information\n",
    "print(\"sample size:\",df.shape[0])\n",
    "age = df['Age'].values\n",
    "print(\"min age:\", np.min(age),\"max age:\",np.max(age),\"mean age:\", np.mean(age),\"std age:\",np.std(age))\n",
    "sex = df['Sex'].values\n",
    "print(\"females:\",np.sum(sex==0),\"males:\",np.sum(sex==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select risky behaviors\n",
    "s = ['eid','2040-2.0','1100-2.0','20160-2.0','Alc','2149-2.0']\n",
    "data1 = tdata[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer Alchol drinks per week and sexual paterners to distinct values \n",
    "# Alcohol: [0,5]-> 1 ; (5,10] -> 2; (10,15] -> 3; (15,20] -> 4; >20 -> 5 \n",
    "# Sexual parteners: 1-1, (1,5]-> 2, (5,10]-3, (10,20]-4, >=20 - 5\n",
    "data1.set_index('eid',inplace=True)\n",
    "Y = data1.loc[tmp_l].values\n",
    "new_Alc = []\n",
    "new_Sex = []\n",
    "for i in range(Y.shape[0]):\n",
    "    if Y[i,-1] == 1:\n",
    "        new_Sex.append(1)\n",
    "    if Y[i,-1] >= 2 and Y[i,-1] <= 5:\n",
    "        new_Sex.append(2)\n",
    "    if Y[i,-1] > 5 and Y[i,-1] <= 10:\n",
    "        new_Sex.append(3)\n",
    "    if Y[i,-1] > 10 and Y[i,-1] <= 20:\n",
    "        new_Sex.append(4)\n",
    "    if Y[i,-1] > 20:\n",
    "        new_Sex.append(5)\n",
    "    \n",
    "    if Y[i,-2] <= 5:\n",
    "        new_Alc.append(1)\n",
    "    if Y[i,-2] > 5 and Y[i,-2] <= 10:\n",
    "        new_Alc.append(2)\n",
    "    if Y[i,-2] > 10 and Y[i,-2] <= 15:\n",
    "        new_Alc.append(3)\n",
    "    if Y[i,-2] > 15 and Y[i,-2] <= 20:\n",
    "        new_Alc.append(4)\n",
    "    if Y[i,-2] > 20:\n",
    "        new_Alc.append(5)\n",
    "\n",
    "RT_data = data1.loc[tmp_l]\n",
    "RT_data['2149-2.0'] = new_Sex\n",
    "RT_data['Alc'] = new_Alc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to conduct the regression of covariates\n",
    "\n",
    "def regression_covariant(covariant_matrix, y, standard_scale=True):\n",
    "    a = np.hstack((covariant_matrix,np.ones((covariant_matrix.shape[0], 1))))\n",
    "    w = np.linalg.lstsq(a,y,rcond=None)[0]\n",
    "\n",
    "    residual = y - covariant_matrix.dot(w[:-1])\n",
    "    residual = residual.astype('float64')\n",
    "\n",
    "    if standard_scale:\n",
    "        residual = StandardScaler().fit_transform(residual.reshape(-1,1)).flatten()\n",
    "\n",
    "    return residual, w\n",
    "\n",
    "def regressing_data(imaging_data,df,imaging_type):\n",
    "    co_cols = ['Age','Sex','IQ','EA']\n",
    "#     co_cols = ['Age','Sex']\n",
    "    if imaging_type == 'CSA':\n",
    "        co_cols.append('TCSA')\n",
    "    \n",
    "    if imaging_type == 'CT':\n",
    "        co_cols.append('ACT')\n",
    "    \n",
    "    if imaging_type == 'ALFF' or imaging_type == 'ReHo':\n",
    "        co_cols.append('motion')\n",
    "    \n",
    "    co = df[co_cols].values\n",
    "    s = imaging_data.shape\n",
    "    reg_imaging_data = np.zeros(s)\n",
    "    for i in range(s[1]):\n",
    "        x = imaging_data.iloc[:,i].values\n",
    "        rx,w = regression_covariant(co,x,standard_scale=False)\n",
    "        reg_imaging_data[:,i] = rx\n",
    "    \n",
    "    return reg_imaging_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance ratio of PCs for risky behaviors: [0.36578415 0.23404963 0.20662033 0.1935459 ]\n",
      "1100-2.0 SpearmanrResult(correlation=0.5298986816070743, pvalue=0.0)\n",
      "20160-2.0 SpearmanrResult(correlation=0.595717677724391, pvalue=0.0)\n",
      "Alc SpearmanrResult(correlation=0.575358717978464, pvalue=0.0)\n",
      "2149-2.0 SpearmanrResult(correlation=0.6466111287997693, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Use PCA to extract the PCs of four risky behaviors\n",
    "# normalization\n",
    "Y_tmp = stats.zscore(RT_data.values[:,1:],axis=0)\n",
    "# PCA analysis\n",
    "pca = PCA(n_components=4)\n",
    "pca_exp = pca.fit(Y_tmp)\n",
    "Y_c = stats.zscore(pca_exp.transform(Y_tmp),axis=0)\n",
    "print(\"explained variance ratio of PCs for risky behaviors:\",pca_exp.explained_variance_ratio_)\n",
    "\n",
    "#correlations between PC1 and four risky behaviors\n",
    "for i in range(4):\n",
    "    print(s[i+2],stats.spearmanr(Y_c[:,0],Y_tmp[:,i]))\n",
    "df_PCs = pd.DataFrame(data=Y_c,columns=['PC1','PC2','PC3','PC4'])\n",
    "df_PCs.to_csv('results/imaging_associations/PCs_risky_behaviors.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the covariance matrix, caluclate the Eigenvalues and the Eigenvectors\n",
    "cov_mat = np.cov(Y_tmp.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "tmp = pd.DataFrame(np.vstack((eigen_vecs,eigen_vals,pca_exp.explained_variance_ratio_)),columns=['PC1','PC2','PC3','PC4'])\n",
    "tmp.to_csv('results/imaging_associations/eigen_vals_and_vecs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressing out covariates\n",
    "reg_CSA_data = regressing_data(CSA_data,df,'CSA')\n",
    "reg_CT_data = regressing_data(CT_data,df,'CT')\n",
    "reg_ALFF_data = regressing_data(ALFF_data,df,'ALFF')\n",
    "reg_ReHo_data = regressing_data(ReHo_data,df,'ReHo')\n",
    "reg_df_PCs1 = regressing_data(df_PCs,df,'CSA')\n",
    "reg_df_PCs2 = regressing_data(df_PCs,df,'CT')\n",
    "reg_df_PCs3 = regressing_data(df_PCs,df,'ALFF')\n",
    "reg_df_PCs4 = regressing_data(df_PCs,df,'ReHo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty array for correlations\n",
    "CSA_corr = np.zeros((len(regions),3))\n",
    "CT_corr = np.zeros((len(regions),3))\n",
    "ALFF_corr = np.zeros((len(regions),3))\n",
    "ReHo_corr = np.zeros((len(regions),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sliu/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# FDR multiple comparison correction\n",
    "from statsmodels.stats import multitest\n",
    "def fdr_correction(data):\n",
    "    Ps = multitest.multipletests(data,alpha=0.05,method='fdr_bh')\n",
    "    return Ps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlations between PCs of risky behaviors and brain measures\n",
    "for PC in range(4):\n",
    "    for j in range(len(regions)):\n",
    "        x1 = reg_CSA_data[:,j]\n",
    "        r,p = stats.spearmanr(x1,reg_df_PCs1[:,PC])\n",
    "        CSA_corr[j,0] = r\n",
    "        CSA_corr[j,1] = p\n",
    "    CSA_corr[:,2] = fdr_correction(CSA_corr[:,1])\n",
    "\n",
    "    for j in range(len(regions)):\n",
    "        x1 = reg_CT_data[:,j]\n",
    "        r,p = stats.spearmanr(x1,reg_df_PCs2[:,PC])\n",
    "        CT_corr[j,0] = r\n",
    "        CT_corr[j,1] = p  \n",
    "    CT_corr[:,2] = fdr_correction(CT_corr[:,1])\n",
    "\n",
    "    for j in range(len(regions)):\n",
    "        x1 = reg_ALFF_data[:,j]\n",
    "        r,p = stats.spearmanr(x1,reg_df_PCs3[:,PC])\n",
    "        ALFF_corr[j,0] = r\n",
    "        ALFF_corr[j,1] = p  \n",
    "    ALFF_corr[:,2] = fdr_correction(ALFF_corr[:,1])\n",
    "\n",
    "    for j in range(len(regions)):\n",
    "        x1 = reg_ReHo_data[:,j]\n",
    "        r,p = stats.spearmanr(x1,reg_df_PCs4[:,PC])\n",
    "        ReHo_corr[j,0] = r\n",
    "        ReHo_corr[j,1] = p  \n",
    "    ReHo_corr[:,2] = fdr_correction(ReHo_corr[:,1])\n",
    "\n",
    "    # save correlations\n",
    "    df1 = pd.DataFrame(data=CSA_corr,columns=['r','p','fdr_p'])\n",
    "    df1['regions'] = regions\n",
    "    df1.to_csv('results/imaging_associations/CSA_corr_PC'+str(PC+1)+'.csv',index=False)\n",
    "    df2 = pd.DataFrame(data=CT_corr,columns=['r','p','fdr_p'])\n",
    "    df2['regions'] = regions\n",
    "    df2.to_csv('results/imaging_associations/CT_corr_PC'+str(PC+1)+'.csv',index=False)\n",
    "    df3 = pd.DataFrame(data=ALFF_corr,columns=['r','p','fdr_p'])\n",
    "    df3['regions'] = regions\n",
    "    df3.to_csv('results/imaging_associations/ALFF_corr_PC'+str(PC+1)+'.csv',index=False)\n",
    "    df4 = pd.DataFrame(data=ReHo_corr,columns=['r','p','fdr_p'])\n",
    "    df4['regions'] = regions\n",
    "    df4.to_csv('results/imaging_associations/ReHo_corr_PC'+str(PC+1)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance ratio of PCs for functional brain associations: [0.83635846 0.16364154]\n"
     ]
    }
   ],
   "source": [
    "# produce the funcPC1 based on brain associations of ALFF and ReHo\n",
    "df1 = pd.read_csv('results/imaging_associations/ALFF_corr_PC1.csv')\n",
    "df2 = pd.read_csv('results/imaging_associations/ReHo_corr_PC1.csv')\n",
    "func_corr = np.vstack((df1['r'].values,df2['r'].values)).T\n",
    "\n",
    "Y_tmp = stats.zscore(func_corr,axis=0)\n",
    "pca = PCA(n_components=2)\n",
    "pca_exp = pca.fit(Y_tmp)\n",
    "Y_c = stats.zscore(pca_exp.transform(Y_tmp),axis=0)\n",
    "print(\"explained variance ratio of PCs for functional brain associations:\",pca_exp.explained_variance_ratio_)\n",
    "\n",
    "df_PCs = pd.DataFrame(data=Y_c,columns=['PC1','PC2'])\n",
    "df_PCs['regions'] = regions\n",
    "df_PCs.to_csv('results/imaging_associations/func_PCs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "associations between ALFF and ReHo: SpearmanrResult(correlation=0.6580732700135685, pvalue=1.922295591643946e-09)\n"
     ]
    }
   ],
   "source": [
    "print(\"associations between ALFF and ReHo:\",stats.spearmanr(df1['r'].values,df2['r'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
